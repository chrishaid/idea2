# A redacted version of airflow.cfg

[core]
airflow_home = /etc/airflow
dags_folder = /etc/airflow/dags
base_log_folder = /var/log/airflow
s3_log_folder = None
#remote_base_log_folder = gs://some-bucket
#remote_log_conn_id = gcp_di
executor = LocalExecutor
sql_alchemy_conn =  postgresql+psycopg2://airflow:airflow@postgres/airflow
parallelism = 64
dag_concurrency = 64
max_active_runs_per_dag = 16
load_examples = False
plugins_folder = /etc/airflow/plugins
#fernet_key = kYaLE7G8dtKsVMfoIuXGl2kLvvDOzkEg0lI9ssKy7N4=
donot_pickle = False
dags_are_paused_at_creation = True

[webserver]
base_url = 127.0.0.0
web_server_host = 0.0.0.0
web_server_port = 8080
#secret_key = test
workers = 4
worker_class = sync
expose_config = false
#authenticate = False
#auth_backend = airflow.contrib.auth.backends.ldap_auth
filter_by_owner = False

[scheduler]
job_heartbeat_sec = 5
scheduler_heartbeat_sec = 5
